{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(['i', 'find', 'most', 'of', 'television', 'so', 'intensely', 'boring', 'that', 'i', 'simply', 'never', 'turn', 'on', 'my', 'set', ',', 'unless', 'i', \"'\", 'm', 'watching', 'a', 'movie', '.', 'i', 'don', \"'\", 't', 'even', 'have', 'cable', ',', 'so', 'i', 'went', 'to', 'radio', 'shack', 'to', 'buy', 'an', 'antenna', 'specifically', 'for', 'the', 'purpose', 'of', 'watching', '\"', 'the', 'x', '-', 'files', '\"', 'every', 'sunday', 'night', '.', 'it', \"'\", 's', 'the', 'only', 'show', 'that', \"'\", 's', 'worth', 'an', 'hour', 'of', 'my', 'time', 'each', 'week', '(', 'though', ',', 'since', 'i', 'don', \"'\", 't', 'watch', 'reruns', ',', 'i', \"'\", 'm', 'glad', 'that', 'i', 'have', 'six', 'months', 'of', 'the', 'year', 'to', 'avoid', 'television', 'altogether', ')', '.', 'i', 'am', 'an', 'avid', 'fan', 'of', 'the', 'show', ',', 'and', 'have', 'been', 'for', 'about', 'three', 'years', 'now', '.', 'and', 'i', 'love', 'gillian', 'anderson', '.', 'the', 'x', '-', 'files', 'is', 'the', 'film', 'that', 'continues', 'the', 'story', 'where', 'the', 'season', 'finale', 'left', 'off', '.', 'the', 'film', 'is', 'like', 'a', 'two', '-', 'hour', 'episode', ',', 'except', 'that', 'there', 'are', 'a', 'lot', 'more', 'special', 'effects', ',', 'the', 'plot', 'is', 'thicker', ',', 'and', 'the', 'resolution', 'is', 'more', 'satisfying', '.', 'this', 'is', 'a', 'terrific', 'film', ',', 'both', 'for', 'fans', 'of', 'the', 'series', 'and', 'for', 'those', 'who', 'have', 'never', 'seen', 'it', '(', 'i', 'imagine', 'that', 'viewers', 'unfamiliar', 'with', 'the', 'show', 'will', 'find', 'the', 'film', 'to', 'be', 'solid', 'and', 'riveting', 'entertainment', ')', '.', 'i', 'expected', 'to', 'like', 'it', 'more', 'than', 'any', 'episode', 'i', \"'\", 've', 'seen', ',', 'and', 'my', 'expectations', 'were', 'met', '.', 'actually', ',', 'the', 'film', 'takes', 'a', 'few', 'risks', 'in', 'its', 'story', 'and', 'plot', 'devices', ',', 'but', ',', 'thankfully', ',', 'the', 'makers', 'managed', 'to', 'do', 'it', 'right', '.', 'when', 'the', 'finale', 'ended', ',', 'the', 'fbi', 'branch', 'known', 'as', 'the', 'x', '-', 'files', 'had', 'been', 'destroyed', ',', 'and', 'our', 'heroes', ',', 'mulder', '(', 'david', 'duchovny', ')', 'and', 'scully', '(', 'gillian', 'anderson', ')', 'were', 'left', 'stripped', 'of', 'five', 'years', 'of', 'hard', 'work', '.', 'the', 'film', 'picks', 'up', 'soon', 'after', ';', 'and', 'mulder', 'and', 'scully', 'have', 'been', 'reduced', 'to', 'field', 'agents', 'investigating', 'a', 'bomb', 'threat', 'in', 'a', 'federal', 'building', '.', 'but', 'wait', ',', 'i', \"'\", 'm', 'getting', 'ahead', 'of', 'myself', '.', 'the', 'film', 'actually', 'opens', 'in', 'the', 'ice', 'age', ',', 'about', '32', ',', '000', 'years', 'prior', ',', 'during', 'which', 'a', 'couple', 'of', 'prehistoric', 'guys', 'get', 'attacked', 'by', 'a', 'vicious', 'alien', '.', 'the', 'alien', \"'\", 's', 'blood', 'infects', 'them', '(', 'fans', 'of', 'the', 'show', 'will', 'certainly', 'remember', 'the', 'black', 'cancer', ')', ',', 'and', 'the', 'story', 'jumps', 'into', 'modern', 'times', ',', 'during', 'which', 'a', 'young', 'boy', 'is', 'also', 'infected', 'with', 'the', 'cancer', '.', 'it', 'turns', 'out', 'that', 'the', 'bomb', 'was', 'planted', 'to', 'kill', 'the', 'boy', ',', 'and', 'mulder', 'and', 'scully', 'uncover', 'the', 'cover', '-', 'up', 'despite', 'the', 'fact', 'that', 'scully', 'has', 'resigned', 'from', 'her', 'position', 'in', 'the', 'fbi', '.', 'soon', ',', 'they', 'find', 'out', 'that', 'the', 'whole', 'thing', 'has', 'to', 'do', 'with', 'aliens', '.', 'as', 'i', \"'\", 've', 'written', 'before', ',', 'it', \"'\", 's', 'not', 'easy', 'to', 'write', 'plot', 'summaries', 'for', 'films', 'like', 'this', ',', 'because', 'everything', 'needs', 'to', 'be', 'a', 'surprise', '.', 'fans', 'of', 'the', 'show', 'will', 'know', 'what', 'to', 'expect', ',', 'and', 'i', 'seriously', 'doubt', 'any', 'of', 'them', 'being', 'disappointed', 'with', 'the', 'film', '.', 'director', 'rob', 'bowman', 'has', 'done', 'a', 'great', 'job', 'expanding', 'the', 'eerie', 'feeling', 'of', 'the', 'show', 'to', 'the', 'big', 'screen', ',', 'making', 'small', 'adjustments', 'and', 'minor', 'changes', 'to', 'utilize', 'the', 'possibilities', 'that', 'film', 'allows', 'over', 'television', '.', 'there', 'are', 'some', 'truly', 'suspenseful', 'and', 'well', '-', 'created', 'scenes', 'here', '(', 'late', 'in', 'the', 'film', ',', 'when', 'they', \"'\", 're', 'in', 'the', 'alien', 'spacecraft', ',', 'you', \"'\", 'll', 'see', 'one', 'of', 'the', 'better', 'action', 'sequences', 'in', 'recent', 'cinema', ')', '.', 'the', 'special', 'effects', 'are', 'very', 'good', ',', 'and', 'the', 'production', 'design', 'by', 'christopher', 'nowak', 'is', 'fantastic', '.', 'what', 'i', 'find', 'interesting', 'is', 'that', 'the', 'x', '-', 'files', 'is', 'actually', 'a', 'great', 'way', 'for', 'series', 'neophytes', 'to', 'get', 'into', 'the', 'story', '.', 'our', 'heroes', 'are', 'given', 'subtle', 'introductions', '(', 'we', \"'\", 're', 'not', 'expected', 'to', 'know', 'them', 'on', 'the', 'outset', ')', ',', 'and', 'the', 'film', 'explains', 'enough', 'of', 'the', 'story', 'that', 'prior', 'knowledge', 'of', 'the', 'series', 'isn', \"'\", 't', 'required', 'to', 'understand', 'the', 'film', '.', 'there', 'are', ',', 'of', 'course', ',', 'little', 'elements', 'that', 'the', 'makers', 'have', 'included', 'as', 'payoff', 'to', 'the', 'fans', ',', 'but', 'i', \"'\", 'll', 'keep', 'those', 'as', 'surprises', '.', 'it', 'takes', 'a', 'lot', 'of', 'thought', 'and', 'understanding', 'of', 'the', 'series', 'to', 'create', 'a', 'film', 'using', 'roots', 'as', 'complicated', 'as', 'the', 'ones', 'that', 'the', 'series', 'provides', ',', 'and', 'then', 'create', 'a', 'coherent', 'film', 'that', 'anyone', 'can', 'understand', 'clearly', '.', 'the', 'series', 'is', 'strong', 'for', 'a', 'lot', 'of', 'reasons', '.', 'it', \"'\", 's', 'original', '(', 'though', 'it', 'has', 'many', 'ties', 'to', '\"', 'the', 'twilight', 'zone', '\"', 'and', 'owes', 'some', 'homage', 'to', 'hitchcock', ')', ',', 'and', 'impressively', 'eerie', 'for', 'a', 'television', 'show', '.', 'what', 'really', 'makes', 'the', 'series', 'shine', ',', 'however', ',', 'are', 'the', 'actors', '.', 'duchovny', 'has', 'so', 'much', 'presence', ',', 'and', 'is', 'just', 'a', 'fun', 'guy', 'to', 'watch', '.', 'he', 'has', 'that', 'confidence', 'that', 'will', 'someday', 'make', 'him', 'into', 'a', 'bankable', 'leading', 'man', '.', 'anderson', 'is', 'equally', 'good', ',', 'and', 'paralyzingly', 'beautiful', ';', 'she', \"'\", 's', 'also', 'a', 'strong', 'actress', '.', 'both', 'performers', 'have', 'acted', 'in', 'little', 'more', 'than', 'their', 'series', ',', 'however', ',', 'though', 'i', 'think', 'they', \"'\", 'll', 'both', 'get', 'their', 'chances', 'to', 'prove', 'themselves', 'very', 'soon', '.', 'i', 'enthusiastically', 'recommend', 'the', 'x', '-', 'files', ',', 'both', 'for', 'fans', 'and', 'non', '-', 'fans', '.', '1998', 'is', 'a', 'summer', 'filled', 'with', 'disappointing', 'blockbusters', ',', 'and', 'this', 'film', 'should', 'satisfy', 'where', 'most', 'of', 'the', 'others', 'leave', 'you', 'completely', 'dry', '.', 'it', \"'\", 's', 'an', 'intelligent', 'film', ',', 'and', 'takes', 'you', 'places', 'that', 'you', 'might', 'not', 'have', 'been', '(', 'or', ',', 'at', 'least', ',', 'might', 'not', 'have', 'seen', 'so', 'many', 'times', 'that', 'they', 'feel', 'familiar', ')', '.', 'the', 'x', '-', 'files', 'is', 'impressive', 'in', 'concept', ',', 'as', 'well', ':', 'fans', 'of', 'the', 'series', 'are', 'likely', 'to', 'be', 'highly', 'critical', ',', 'and', 'to', 'take', 'the', 'premise', 'beyond', 'the', 'series', 'is', 'a', 'risky', 'move', '.', 'it', \"'\", 's', 'nice', 'to', 'see', 'a', 'risk', 'pay', 'off', 'for', 'a', 'change', '.', 'actually', ',', 'it', \"'\", 's', 'nice', 'to', 'see', 'a', 'risk', 'at', 'all', '.'], 'pos')\n"
    }
   ],
   "source": [
    "import nltk\n",
    "import random\n",
    "from nltk.corpus import movie_reviews\n",
    "\n",
    "documents = []\n",
    "\n",
    "# documents = [(list(movie_reviews.words(fileid)), category)\n",
    "#              for category in movie_reviews.categories()\n",
    "#              for fileid in movie_reviews.fileids(category)]\n",
    "\n",
    "for category in movie_reviews.categories():\n",
    "    for fileid in movie_reviews.fileids(category):\n",
    "        documents.append((list(movie_reviews.words(fileid)), category))\n",
    "\n",
    "random.shuffle(documents)\n",
    "\n",
    "print(documents[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[(',', 77717), ('the', 76529), ('.', 65876), ('a', 38106), ('and', 35576), ('of', 34123), ('to', 31937), (\"'\", 30585), ('is', 25195), ('in', 21822), ('s', 18513), ('\"', 17612), ('it', 16107), ('that', 15924), ('-', 15595)]\n"
    }
   ],
   "source": [
    "all_words = []\n",
    "\n",
    "for w in movie_reviews.words():\n",
    "    all_words.append(w.lower())\n",
    "\n",
    "all_words = nltk.FreqDist(all_words)\n",
    "\n",
    "print(all_words.most_common(15)) # 15 most common words in all movie reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "253\n"
    }
   ],
   "source": [
    "print(all_words[\"stupid\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Words as Feature for Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "from nltk.corpus import movie_reviews\n",
    "\n",
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "             for category in movie_reviews.categories()\n",
    "             for fileid in movie_reviews.fileids(category)]\n",
    "\n",
    "random.shuffle(documents)\n",
    "\n",
    "all_words = []\n",
    "\n",
    "for w in movie_reviews.words():\n",
    "    all_words.append(w.lower())\n",
    "\n",
    "all_words = nltk.FreqDist(all_words)\n",
    "\n",
    "word_features = list(all_words.keys())[:3000]\n",
    "\n",
    "def find_features(document):\n",
    "    words = set(document)\n",
    "    features = {}\n",
    "    for w in word_features:\n",
    "        features[w] = (w in words)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "FreqDist({',': 77717, 'the': 76529, '.': 65876, 'a': 38106, 'and': 35576, 'of': 34123, 'to': 31937, \"'\": 30585, 'is': 25195, 'in': 21822, ...})"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['plot',\n ':',\n 'two',\n 'teen',\n 'couples',\n 'go',\n 'to',\n 'a',\n 'church',\n 'party',\n ',',\n 'drink',\n 'and',\n 'then',\n 'drive',\n '.',\n 'they',\n 'get',\n 'into',\n 'an']"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "word_features[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "': False, 'higher': False, 'semi': False, 'saving': False, 'grace': False, 'wise': False, 'irrepressible': False, 'once': False, 'thousand': False, 'god': False, 'beg': False, 'agent': False, 'marketplace': False, 'modern': False, 'day': False, 'roles': False, 'romantic': False, 'gunk': False, 'alright': False, 'yeah': False, 'yikes': False, 'notches': False, 'fellas': False, 'blares': False, 'ear': False, 'accentuate': False, 'annoy': False, 'important': False, 'behind': False, 'recognize': False, 'epic': False, 'fluffy': False, 'rehashed': False, 'cake': False, 'created': False, 'shrewd': False, 'advantage': False, 'kung': False, 'fu': False, 'phenomenon': False, 'test': False, 'dudes': False, 'keep': False, 'reading': False, 'editing': False, 'shoddy': False, 'banal': False, 'stilted': False, 'plentiful': False, 'top': False, 'horse': False, 'carriage': False, 'stand': False, 'opponent': False, 'scampering': False, 'cut': False, 'mouseketeer': False, 'rope': False, 'tower': False, 'jumping': False, 'chords': False, 'hanging': False, 'says': False, '14': False, 'shirt': False, 'strayed': False, 'championing': False, 'fun': False, 'stretches': False, 'atrocious': False, 'lake': False, 'reminded': False, 'school': False, 'cringe': False, 'musketeers': False, 'fat': False, 'raison': False, 'etre': False, 'numbers': False, 'hoping': False, 'packed': False, 'stuntwork': False, 'promoted': False, 'trailer': False, 'major': False, 'swashbuckling': False, 'beginning': False, 'finishes': False, 'juggling': False, 'ladders': False, 'ladder': False, 'definite': False, 'keeper': False, 'regurgitated': False, 'crap': False, 'tell': False, 'deneuve': False, 'placed': False, 'hullo': False, 'barely': False, 'ugh': False, 'small': False, 'annoyed': False, 'trash': False, 'gang': False, 'vow': False, 'stay': False, 'thank': False, 'outlaws': False, '5': False, 'crouching': False, 'tiger': False, 'hidden': False, 'matrix': False, 'replacement': False, 'killers': False, '6': False, 'romeo': False, 'die': False, 'shanghai': False, 'noon': False, 'remembered': False, 'dr': False, 'hannibal': False, 'lecter': False, 'michael': False, 'mann': False, 'forensics': False, 'thriller': False, 'manhunter': False, 'scottish': False, 'brian': False, 'cox': False, 'works': False, 'usually': False, 'schlock': False, 'halfway': False, 'goodnight': False, 'meaty': False, 'substantial': False, 'brilliant': False, 'check': False, 'dogged': False, 'inspector': False, 'opposite': False, 'frances': False, 'mcdormand': False, 'ken': False, 'loach': False, 'agenda': False, 'harrigan': False, 'disturbing': False, 'l': False, 'e': False, '47': False, 'picked': False, 'sundance': False, 'distributors': False, 'scared': False, 'budge': False, 'dares': False, 'speak': False, 'expresses': False, 'seeking': False, 'adolescents': False, 'pad': False, 'bothered': False, 'members': False, 'presentation': False, 'oddly': False, 'empathetic': False, 'light': False, 'tempered': False, 'robust': False, 'listens': False, 'opposed': False, 'friends': False, 'wire': False, 'act': False, 'confused': False, 'lives': False, 'pay': False, 'courtship': False, 'charming': False, 'temptations': False, 'grown': False, 'stands': False, 'island': False, 'expressway': False, 'slices': False, 'malls': False, 'class': False, 'homes': False, 'suburbia': False, 'filmmaker': False, 'cuesta': False, 'uses': False, 'transparent': False, 'metaphor': False, '15': False, 'protagonist': False, 'howie': False, 'franklin': False, 'dano': False, 'reveals': False, 'morbid': False, 'preoccupation': False, 'death': False, 'citing': False, 'deaths': False, 'alan': False, 'j': False, 'pakula': False, 'songwriter': False, 'harry': False, 'chapin': False, 'exit': False, '52': False, 'fascinated': False, 'feelings': False, 'projected': False, 'bright': False, 'move': False, 'force': False, 'complex': False, 'molesters': False, 'beast': False, 'ashamed': False, 'worked': False, 'ill': False, 'advised': False, 'foray': False, 'unnecessary': False, 'padding': False, 'miserable': False, 'bruce': False, 'altman': False, 'seat': False, 'collar': False, 'crime': False, 'degenerate': False, 'youngsters': False, 'kicks': False, 'robbing': False, 'houses': False, 'homoerotic': False, 'shenanigans': False, 'ass': False, 'terrio': False, 'billy': False, 'kay': False, 'handsome': False, 'artful': False, 'dodger': False, 'add': False, 'themes': False, 'suburban': False, 'ennui': False, 'needed': False, 'awkward': False, 'subplots': False, 'concurrently': False, 'relationship': False, 'evenly': False, 'paced': False, 'exceptionally': False, 'acted': False, 'sporting': False, 'baseball': False, 'cap': False, 'faded': False, 'marine': False, 'tattoo': False, 'bluff': False, 'bluster': False, 'quiet': False, 'glance': False, 'withdrawn': False, 'whose': False, 'dramatic': False, 'choices': False, 'broad': False, 'calling': False, 'haley': False, 'restraint': False, 'admirable': False, 'screenplay': False, 'material': False, 'reads': False, 'walt': False, 'whitman': False, 'poem': False, 'moment': False, 'precious': False, 'lingers': False, 'ecstatic': False, 'hearing': False, 'glenn': False, 'gould': False, 'performing': False, 'bach': False, 'goldberg': False, 'variations': False, 'involving': False, 'walter': False, 'masterson': False, 'jealous': False, 'newbie': False, 'thread': False, 'predictably': False, 'leads': False, 'observational': False, 'portrait': False, 'alienation': False, 'royally': False, 'screwed': False, 'terry': False, 'zwigoff': False, 'superb': False, 'confidence': False, 'ambivalent': False, 'typical': False, 'cinema': False, 'wrap': False, 'bullet': False, 'sparing': False, 'writers': False, 'philosophical': False, 'regard': False, 'countless': False, 'share': False, 'blockbuster': False, 'solved': False, 'obstacle': False, 'removed': False, 'often': False, 'extend': False, 'question': False, 'striving': False, 'realism': False, 'destroy': False, 'janeane': False, 'garofalo': False, 'couple': False, 'truth': False, 'cats': False, 'dogs': False, 'excruciating': False, 'matchmaker': False, 'books': False, 'plods': False, 'predestined': False, 'surprises': False, 'jumps': False, 'popular': False, 'political': False, 'satire': False, 'bandwagon': False, 'campaign': False, 'aide': False, 'massacusetts': False, 'senator': False, 'sanders': False, 'reelection': False, 'denis': False, 'leary': False, 'stereotypical': False, 'strategist': False, 'ethics': False, 'scandal': False, 'plagued': False, 'play': False, 'irish': False, 'roots': False, 'boston': False, 'roman': False, 'catholic': False, 'democrat': False, 'contingent': False, 'kennedy': False, 'family': False, 'orders': False, 'ireland': False, 'relatives': False, 'exploit': False, 'soon': False, 'learns': False, 'said': False, 'done': False, 'mantra': False, 'tiny': False, 'misses': False, 'bus': False, 'hotel': False, 'ends': False, 'smallest': False, 'trashiest': False, 'dog': False, 'luggage': False, 'roger': False, 'ebert': False, 'calls': False, 'meet': False, 'happens': False, 'unconventional': False, 'cinematic': False, 'walks': False, 'bathroom': False, 'nude': False, 'sean': False, 'david': False, 'hara': False, 'bathtub': False, 'points': False, 'guessing': False, 'water': False, 'hates': False, 'instant': False, 'saw': False, 'irishman': False, 'hate': False, 'awhile': False, 'succumb': False, 'charms': False, 'happily': False, 'superficial': False, 'detail': False, 'throw': False, 'turmoil': False, 'reconcile': False, 'tune': False, 'annual': False, 'matchmaking': False, 'festival': False, 'lonely': False, 'county': False, 'future': False, 'bliss': False, 'milo': False, 'shea': False, 'snyder': False, 'pops': False, 'onscreen': False, 'spew': False, 'souls': False, 'assured': False, 'match': False, 'utter': False, 'predictability': False, 'message': False, 'respectable': False, 'person': False, 'comedic': False, 'distinction': False, 'sell': False, 'script': False, 'excited': False, 'stays': False, 'stateside': False, 'yelling': False, 'phone': False, 'undoes': False, 'microphone': False, 'speech': False, 'known': False, 'flying': False, 'hong': False, 'kong': False, 'style': False, 'filmmaking': False, 'classics': False, 'nod': False, 'asia': False, 'france': False, 'lukewarm': False, 'dumas': False, 'asian': False, 'stunt': False, 'coordinator': False, 'xing': False, 'xiong': False, 'prior': False, 'attempts': False, 'choreography': False, 'laughable': False, 'van': False, 'damme': False, 'vehicle': False, 'team': False, 'dennis': False, 'rodman': False, 'simon': False, 'sez': False, 'thrown': False, 'air': False, 'result': False, 'tepid': False, 'adventure': False, 'rip': False, 'stinks': False, 'indiana': False, 'jones': False, 'simple': False, 'grandmother': False, 'adapted': False, 'artagnan': False, 'vengeful': False, 'son': False, 'slain': False, 'travels': False, 'paris': False, 'join': False, 'royal': False, 'meets': False, 'cunning': False, 'cardinal': False, 'richelieu': False, 'stephen': False, 'rea': False, 'overthrow': False, 'associate': False, 'febre': False, 'killer': False, 'disbanded': False, 'rounds': False, 'aramis': False, 'nick': False, 'moran': False, 'athos': False, 'jan': False, 'gregor': False, 'kremp': False, 'porthos': False, 'steven': False, 'spiers': False, 'wrongfully': False, 'imprisoned': False, 'leader': False, 'treville': False, 'prison': False, 'frisky': False, 'interest': False, 'chambermaid': False, 'francesca': False, 'footsy': False, 'coo': False, 'hunts': False, 'queen': False, 'captured': False, 'menancing': False, 'forcing': False, 'regroup': False, 'leading': False, 'charge': False, 'peter': False, 'hyams': False, 'wanted': False, 'blend': False, 'eastern': False, 'western': False, 'styles': False, 'disaster': False, 'reality': False, 'ones': False, 'jet': False, 'li': False, 'risk': False, 'ironically': False, 'swordplay': False, 'spread': False, 'carry': False, 'bulk': False, '30': False, 'minute': False, 'picture': False, 'weighs': False, 'monotonous': False, 'gene': False, 'quintano': False, 'prosaic': False, 'wedding': False, 'planner': False, 'mousy': False, 'artangnan': False, 'hyam': False, 'candles': False, 'torches': False, 'grime': False, 'filth': False, '17th': False, 'noted': False, 'standout': False, 'mortal': False, 'kombat': False, 'annihilation': False, 'reviewed': False, 'multiple': False, 'levels': False, 'rampant': False, 'usage': False, 'randian': False, 'subtext': False, 'pervades': False, 'occasionaly': False, 'ironic': False, 'depreciating': False, 'remark': False, 'tosses': False, 'clearly': False, 'marxist': False, 'imagery': False, 'kidding': False, 'seriousness': False, 'fair': False, '*': False, 'necessary': False, 'viewpoints': False, 'watcher': False, 'unfamiliar': False, 'marginally': False, 'fan': False, 'games': False, '1995': False, 'concerned': False, 'martial': False, 'arts': False, 'tournament': False, 'decide': False, 'fate': False, 'billion': False, 'inhabitants': False, 'mortals': False, 'theory': False, 'prevented': False, 'emperor': False, 'shao': False, 'khan': False, 'arriving': False, 'ready': False, 'assumed': False, 'stance': False, 'extraordinarily': False, 'myself': False, 'game': False, 'enjoyed': False, 'directors': False, 'knew': False, 'limitations': False, 'try': False, 'overachieve': False, 'accompanying': False, 'intersperesed': False, 'distracting': False, 'non': False, 'intrusive': False, 'bits': False, 'fluff': False, 'passing': False, 'smashing': False, 'success': False, 'box': False, 'office': False, 'picks': False, 'precisely': False, 'introductory': False, 'exposition': False, 'anyways': False, 'hell': False, 'silly': False, 'rule': False, 'winning': False, 'thereafter': False, 'approximately': False, '85': False, 'alternates': False, 'general': False, 'impression': False, 'producers': False, 'thought': False, 'formula': False, 'volumes': False, 'truly': False, 'sandra': False, 'hess': False, 'sonya': False, 'blade': False, 'execrable': False, 'convince': False, 'loved': False, 'johnny': False, 'greased': False, 'worst': False, 'mis': False, 'james': False, 'remar': False, 'raiden': False, 'thunder': False, 'christopher': False, 'lambert': False, 'japanese': False, 'revered': False, 'chinese': False, 'mystics': False, 'against': False, 'lister': False, 'jr': False, 'president': False, 'u': False, 'fifth': False, 'utility': False, 'totally': False, 'luxury': False, 'amused': False, 'awareness': False, 'introduced': False, 'meaningless': False, 'sidetracks': False, 'including': False, 'muddled': False, 'liu': False, 'kang': False, 'shou': False, 'seeks': False, 'nightwolf': False, 'litefoot': False, 'mystical': False, 'hallucination': False, 'jade': False, 'irina': False, 'pantaeva': False, 'reasons': False, 'unless': False, 'critiques': False, 'apply': False, 'worse': False, 'bridgette': False, 'convincing': False, 'looked': False, 'mimicing': False, 'movements': False, 'choreographer': False, 'knows': False, 'puts': False, 'believable': False, 'jax': False, 'earthquake': False, 'animality': False, 'bonus': False, 'similar': False, 'moves': False, 'mistakenly': False, 'hang': False, 'lamest': False, 'involved': False, 'mud': False, 'wrestling': False, 'lame': False, 'politically': False, 'incorrect': False, 'noticed': False, 'remarked': False, 'upon': False, 'emporer': False, 'perform': False, 'animalities': False, 'motaro': False, 'sheeva': False, 'lifelike': False, 'goro': False, 'enjoy': False, 'femme': False, 'la': False, 'nikita': False, 'backdraft': False, 'sliver': False, 'cindy': False, 'crawford': False, 'anne': False, 'parillaud': False, 'conspire': False, 'shattered': False, 'image': False, 'hooey': False, 'stallone': False, 'stone': False, 'specialist': False, 'poses': False, 'recurring': False, 'assassin': False, 'honeymooning': False, 'jamaica': False, 'believe': False, 'runs': False, 'painful': False, 'pedestrian': False, 'siouxsie': False, 'sioux': False, 'wig': False, 'emotionless': False, 'leather': False, 'clothing': False, 'seattle': False, 'moping': False, 'karen': False, 'endlessly': False, 'complicated': False, 'plots': False, 'helps': False, 'crisp': False, 'modicum': False, 'shakespearean': False, 'begin': False, 'saddled': False, 'leaden': False, 'zero': False, 'breaking': False, 'cardboard': False, 'confines': False, 'insist': False, 'couldn': False, 'huh': False, 'wonderful': False, 'interchange': False, 'charm': False, 'faster': False, 'learned': False, 'cereal': False, 'crybaby': False, 'imagines': False, 'stranger': False, 'sends': False, 'flowers': False, 'chromium': False, 'tough': False, 'nails': False, 'crack': False, 'killing': False, 'machine': False, 'shoots': False, 'mirrors': False, 'stock': False, 'interested': False, 'nest': False, 'egg': False, 'pave': False, 'paradise': False, 'put': False, 'parking': False, 'graham': False, 'greene': False, 'barbet': False, 'schroeder': False, 'reversal': False, 'fortune': False, 'co': False, 'produced': False, 'agonizingly': False, 'b': False, 'york': False, 'vampires': False, 'latest': False, 'opus': False, 'bent': False, 'outing': False, 'aptly': False, 'titled': False, 'suppose': False, 'went': False, 'prefixed': False, 'possessive': False, 'unashamed': False, 'punctuated': False, 'above': False, 'storyline': False, 'borders': False, 'idiotic': False, 'chaotic': False, 'dormant': False, 'martians': False, 'swirling': False, 'gases': False, 'awakened': False, 'meddling': False, 'possess': False, 'hapless': False, 'colonists': False, 'testy': False, 'marilyn': False, 'manson': False, 'lookalikes': False, 'pooh': False, 'bah': False, 'counsel': False, 'official': False, 'melanie': False, 'ballard': False, 'natasha': False, 'henstridge': False, 'sub': False, 'species': False, 'returnee': False, 'officer': False, 'incarcerated': False, 'felon': False, 'second': False, 'blonde': False, 'pulled': False, 'tightly': False, 'awkwardly': False, 'ponytail': False, 'ice': False, 'cube': False, 'appropriately': False, 'named': False, 'pam': False, 'grier': False, 'briefly': False, 'whom': False, 'wonder': False, 'host': False, 'extras': False, 'therefore': False, 'bird': False, 'shots': False, 'sprawling': False, 'metropolis': False, 'reddish': False, 'state': False, 'art': False, 'trademark': False, 'finding': False, 'department': False, 'lock': False, 'laughing': False, 'barrel': False, 'fare': False, 'dingy': False, 'interiors': False, 'cluttered': False, 'exteriors': False, 'inane': False, 'lots': False, 'scarred': False, 'crazed': False, 'aliens': False, 'weaponry': False, 'warfare': False, 'warning': False, 'spontaneously': False, 'stupidly': False, 'villains': False, 'border': False, 'conflicts': False, 'shootouts': False, 'minus': False, 'hissing': False, 'plissken': False, 'miss': False, 'dubbed': False, 'minimalist': False, 'soundtracks': False, 'graduated': False, 'effective': False, 'scoring': False, 'highlighting': False, 'screeching': False, 'guitar': False, 'fortunately': False, 'drowns': False, 'er': False, 'audible': False, 'priceless': False, 'proven': False, 'infertile': False, 'breeding': False, 'ground': False, 'stillborn': False, 'val': False, 'kilmer': False, 'disappointing': False, 'weekend': False, 'overshadowed': False, 'sequels': False, 'among': False, 'pie': False, 'rush': False, 'absent': False, 'references': False, 'set': False, 'perth': False, 'amboys': False, 'closest': False, 'neighbor': False, 'slap': False, 'upside': False, '1': False, 'keeps': False, 'miraculously': False, 'pretend': False, 'means': False, 'intelligent': False, 'grade': False, 'sci': False, 'fi': False, 'singularly': False, 'luck': False, 'starting': False, 'alicia': False, 'silverstone': False, 'beautiful': False, 'creatures': False, 'green': False, 'critic': False, 'large': False, 'choosing': False, 'strikes': False, 'crush': False, 'slow': False, 'moving': False, 'horrific': False, 'adaptation': False, 'clueless': False, 'mailed': False, 'saying': False, 'theater': False, 'expecting': False, 'preview': False, 'crazymadinlove': False, 'whiny': False, 'unlikable': False, 'wasn': False, 'yelled': False, 'f': False, '$&#': False, 'laugh': False, 'agreement': False, 'walked': False, 'babysitter': False, 'inner': False, 'compulsion': False, 'understand': False, 'rent': False, 'regret': False, 'paragraph': False, 'competition': False, 'criticizing': False, 'thin': False, 'shred': False, 'slower': False, 'glacier': False, 'writing': False, 'appeal': False, 'whatsoever': False, 'pointlessly': False, 'concluded': False, 'violent': False, 'plus': False, 'equals': False, 'spends': False, 'twenty': False, 'bubble': False, 'bath': False, 'joined': False, 'four': False, 'features': False, 'settle': False, 'friday': False, 'cocktail': False, 'automatically': False, 'nights': False, 'trods': False, 'discover': False, 'silent': False, 'object': False, 'male': False, 'fantasies': False, 'thinks': False, 'recapture': False, 'youth': False, 'boyfriend': False, 'lets': False, 'wild': False, 'spying': False, 'outside': False, 'prepubescent': False, 'keyhole': False, 'aged': False, 'counterpart': False, 'asked': False, '200': False, 'pound': False, 'silk': False, 'teddy': False, 'fanatasies': False, 'realm': False, 'pg': False, 'imagine': False, 'cinemax': False, 'staple': False, 'absolutely': False, 'pointed': False, 'classify': False, 'mix': False, 'various': False, 'encounters': False, 'third': False, 'space': False, 'odyssey': False, 'apollo': False, 'contact': False, 'hope': False, 'melange': False, 'considering': False, 'disastrous': False, 'results': False, 'sucks': False, 'rescue': False, 'astronauts': False, 'sent': False, '2020': False, 'unknown': False, 'aviators': False, 'visit': False, 'underwhelming': False, 'describe': False, 'uneven': False, 'promise': False, 'buzz': False, 'neutral': False, 'cherry': False, 'colored': False, 'nerdies': False, 'techie': False}\n"
    }
   ],
   "source": [
    "print((find_features(movie_reviews.words('neg/cv000_29416.txt')))) # Example printing\n",
    "\n",
    "featuresets = [(find_features(rev), category) for (rev, category) in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "3000"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "len(featuresets[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Naive Bayes Algo Accuracy:  78.0\nMost Informative Features\n                   sucks = True              neg : pos    =      9.8 : 1.0\n                 idiotic = True              neg : pos    =      9.2 : 1.0\n                  annual = True              pos : neg    =      9.0 : 1.0\n                  turkey = True              neg : pos    =      8.4 : 1.0\n                 frances = True              pos : neg    =      7.7 : 1.0\n                  regard = True              pos : neg    =      7.0 : 1.0\n           unimaginative = True              neg : pos    =      7.0 : 1.0\n               atrocious = True              neg : pos    =      6.6 : 1.0\n              schumacher = True              neg : pos    =      6.6 : 1.0\n                obstacle = True              pos : neg    =      6.4 : 1.0\n                 singers = True              pos : neg    =      6.4 : 1.0\n                 kidding = True              neg : pos    =      6.3 : 1.0\n                    mena = True              neg : pos    =      6.3 : 1.0\n                  shoddy = True              neg : pos    =      6.3 : 1.0\n             silverstone = True              neg : pos    =      6.3 : 1.0\n"
    }
   ],
   "source": [
    "training_set = featuresets[:1900]\n",
    "testing_set = featuresets[1900:]\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(training_set)\n",
    "\n",
    "print(\"Naive Bayes Algo Accuracy: \", (nltk.classify.accuracy(classifier, testing_set)) * 100)\n",
    "classifier.show_most_informative_features(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Classifier with Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "save_classifier = open(\"naivebayes.pickle\",\"wb\")\n",
    "pickle.dump(classifier, save_classifier)\n",
    "save_classifier.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Naive Bayes Algo Accuracy:  78.0\nMost Informative Features\n                   sucks = True              neg : pos    =      9.8 : 1.0\n                 idiotic = True              neg : pos    =      9.2 : 1.0\n                  annual = True              pos : neg    =      9.0 : 1.0\n                  turkey = True              neg : pos    =      8.4 : 1.0\n                 frances = True              pos : neg    =      7.7 : 1.0\n                  regard = True              pos : neg    =      7.0 : 1.0\n           unimaginative = True              neg : pos    =      7.0 : 1.0\n               atrocious = True              neg : pos    =      6.6 : 1.0\n              schumacher = True              neg : pos    =      6.6 : 1.0\n                obstacle = True              pos : neg    =      6.4 : 1.0\n                 singers = True              pos : neg    =      6.4 : 1.0\n                 kidding = True              neg : pos    =      6.3 : 1.0\n                    mena = True              neg : pos    =      6.3 : 1.0\n                  shoddy = True              neg : pos    =      6.3 : 1.0\n             silverstone = True              neg : pos    =      6.3 : 1.0\n"
    }
   ],
   "source": [
    "training_set = featuresets[:1900]\n",
    "testing_set = featuresets[1900:]\n",
    "\n",
    "classifier_f = open(\"naivebayes.pickle\",\"rb\")\n",
    "classifier = pickle.load(classifier_f) # We are loading our classifier with pickle, rather than training it again.\n",
    "classifier_f.close()\n",
    "\n",
    "print(\"Naive Bayes Algo Accuracy: \", (nltk.classify.accuracy(classifier, testing_set)) * 100)\n",
    "classifier.show_most_informative_features(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sci-kit Learn Incorporation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Original Naive Bayes Algo Accuracy:  76.0\nMost Informative Features\n              schumacher = True              neg : pos    =     11.7 : 1.0\n                   sucks = True              neg : pos    =      9.8 : 1.0\n                  annual = True              pos : neg    =      9.7 : 1.0\n                 frances = True              pos : neg    =      9.0 : 1.0\n           unimaginative = True              neg : pos    =      8.3 : 1.0\n                 idiotic = True              neg : pos    =      7.2 : 1.0\n                  sexist = True              neg : pos    =      7.0 : 1.0\n             silverstone = True              neg : pos    =      7.0 : 1.0\n               atrocious = True              neg : pos    =      7.0 : 1.0\n                  regard = True              pos : neg    =      6.6 : 1.0\n                  turkey = True              neg : pos    =      6.6 : 1.0\n                 kidding = True              neg : pos    =      6.3 : 1.0\n                    mena = True              neg : pos    =      6.3 : 1.0\n                obstacle = True              pos : neg    =      6.3 : 1.0\n                 singers = True              pos : neg    =      6.3 : 1.0\nMNB_classifier Algo Accuracy:  78.0\nBernoulliNB_classifier Algo Accuracy:  75.0\nLogisticRegression_classifier Algo Accuracy:  71.0\nSGDClassifier_classifier Algo Accuracy:  77.0\nSVC_classifier Algo Accuracy:  76.0\nLinearSVC_classifier Algo Accuracy:  72.0\nNuSVC_classifier Algo Accuracy:  75.0\n"
    }
   ],
   "source": [
    "import nltk\n",
    "import random\n",
    "from nltk.corpus import movie_reviews\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "\n",
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "             for category in movie_reviews.categories()\n",
    "             for fileid in movie_reviews.fileids(category)]\n",
    "\n",
    "random.shuffle(documents)\n",
    "\n",
    "all_words = []\n",
    "\n",
    "for w in movie_reviews.words():\n",
    "    all_words.append(w.lower())\n",
    "\n",
    "all_words = nltk.FreqDist(all_words)\n",
    "\n",
    "word_features = list(all_words.keys())[:3000]\n",
    "\n",
    "def find_features(document):\n",
    "    words = set(document)\n",
    "    features = {}\n",
    "    for w in word_features:\n",
    "        features[w] = (w in words)\n",
    "\n",
    "    return features\n",
    "\n",
    "featuresets = [(find_features(rev), category) for (rev, category) in documents]\n",
    "\n",
    "training_set = featuresets[:1900]\n",
    "testing_set = featuresets[1900:]\n",
    "\n",
    "# Original\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(training_set)\n",
    "\n",
    "print(\"Original Naive Bayes Algo Accuracy: \", (nltk.classify.accuracy(classifier, testing_set)) * 100)\n",
    "classifier.show_most_informative_features(15)\n",
    "\n",
    "# Multinomial\n",
    "\n",
    "MNB_classifier = SklearnClassifier(MultinomialNB())\n",
    "MNB_classifier.train(training_set)\n",
    "\n",
    "print(\"MNB_classifier Algo Accuracy: \", (nltk.classify.accuracy(MNB_classifier, testing_set)) * 100)\n",
    "\n",
    "# BernoulliNB\n",
    "\n",
    "BernoulliNB_classifier = SklearnClassifier(BernoulliNB())\n",
    "BernoulliNB_classifier.train(training_set)\n",
    "\n",
    "print(\"BernoulliNB_classifier Algo Accuracy: \", (nltk.classify.accuracy(BernoulliNB_classifier, testing_set)) * 100)\n",
    "\n",
    "# LogisticRegression\n",
    "\n",
    "LogisticRegression_classifier = SklearnClassifier(LogisticRegression())\n",
    "LogisticRegression_classifier.train(training_set)\n",
    "\n",
    "print(\"LogisticRegression_classifier Algo Accuracy: \", (nltk.classify.accuracy(LogisticRegression_classifier, testing_set)) * 100)\n",
    "\n",
    "# SGDClassifier\n",
    "\n",
    "SGDClassifier_classifier = SklearnClassifier(SGDClassifier())\n",
    "SGDClassifier_classifier.train(training_set)\n",
    "\n",
    "print(\"SGDClassifier_classifier Algo Accuracy: \", (nltk.classify.accuracy(SGDClassifier_classifier, testing_set)) * 100)\n",
    "\n",
    "# SVC\n",
    "\n",
    "SVC_classifier = SklearnClassifier(SVC())\n",
    "SVC_classifier.train(training_set)\n",
    "\n",
    "print(\"SVC_classifier Algo Accuracy: \", (nltk.classify.accuracy(SVC_classifier, testing_set)) * 100)\n",
    "\n",
    "# LinearSVC\n",
    "\n",
    "LinearSVC_classifier = SklearnClassifier(LinearSVC())\n",
    "LinearSVC_classifier.train(training_set)\n",
    "\n",
    "print(\"LinearSVC_classifier Algo Accuracy: \", (nltk.classify.accuracy(LinearSVC_classifier, testing_set)) * 100)\n",
    "\n",
    "# NuSVC\n",
    "\n",
    "NuSVC_classifier = SklearnClassifier(NuSVC())\n",
    "NuSVC_classifier.train(training_set)\n",
    "\n",
    "print(\"NuSVC_classifier Algo Accuracy: \", (nltk.classify.accuracy(NuSVC_classifier, testing_set)) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining algos with a vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Original Naive Bayes Algo Accuracy:  76.0\nMNB_classifier Algo Accuracy:  78.0\nBernoulliNB_classifier Algo Accuracy:  75.0\nLogisticRegression_classifier Algo Accuracy:  71.0\nSGDClassifier_classifier Algo Accuracy:  72.0\nLinearSVC_classifier Algo Accuracy:  72.0\nNuSVC_classifier Algo Accuracy:  75.0\nVoted_classifier Algo Accuracy:  76.0\nClassfication:  neg Confidence %:  71.42857142857143\nClassfication:  neg Confidence %:  100.0\nClassfication:  neg Confidence %:  57.14285714285714\nClassfication:  pos Confidence %:  100.0\nClassfication:  neg Confidence %:  100.0\nClassfication:  pos Confidence %:  100.0\n"
    }
   ],
   "source": [
    "import nltk\n",
    "import random\n",
    "from nltk.corpus import movie_reviews\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "\n",
    "from nltk.classify import ClassifierI\n",
    "from statistics import mode\n",
    "\n",
    "class VoteClassifier(ClassifierI):\n",
    "\n",
    "    def __init__(self, *classifiers):\n",
    "        self._classifiers = classifiers\n",
    "\n",
    "    def classify(self, features):\n",
    "        votes = []\n",
    "\n",
    "        for c in self._classifiers:\n",
    "            v = c.classify(features)\n",
    "            votes.append(v)\n",
    "            return mode(votes)\n",
    "\n",
    "    def confidence(self, features):\n",
    "        votes = []\n",
    "\n",
    "        for c in self._classifiers:\n",
    "            v = c.classify(features)\n",
    "            votes.append(v)\n",
    "        choice_votes = votes.count(mode(votes))\n",
    "        conf = choice_votes / len(votes)\n",
    "        return conf\n",
    "\n",
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "             for category in movie_reviews.categories()\n",
    "             for fileid in movie_reviews.fileids(category)]\n",
    "\n",
    "random.shuffle(documents)\n",
    "\n",
    "all_words = []\n",
    "\n",
    "for w in movie_reviews.words():\n",
    "    all_words.append(w.lower())\n",
    "\n",
    "all_words = nltk.FreqDist(all_words)\n",
    "\n",
    "word_features = list(all_words.keys())[:3000]\n",
    "\n",
    "def find_features(document):\n",
    "    words = set(document)\n",
    "    features = {}\n",
    "    for w in word_features:\n",
    "        features[w] = (w in words)\n",
    "\n",
    "    return features\n",
    "\n",
    "featuresets = [(find_features(rev), category) for (rev, category) in documents]\n",
    "\n",
    "training_set = featuresets[:1900]\n",
    "testing_set = featuresets[1900:]\n",
    "\n",
    "# Original\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(training_set)\n",
    "\n",
    "print(\"Original Naive Bayes Algo Accuracy: \", (nltk.classify.accuracy(classifier, testing_set)) * 100)\n",
    "\n",
    "# Multinomial\n",
    "\n",
    "MNB_classifier = SklearnClassifier(MultinomialNB())\n",
    "MNB_classifier.train(training_set)\n",
    "\n",
    "print(\"MNB_classifier Algo Accuracy: \", (nltk.classify.accuracy(MNB_classifier, testing_set)) * 100)\n",
    "\n",
    "# BernoulliNB\n",
    "\n",
    "BernoulliNB_classifier = SklearnClassifier(BernoulliNB())\n",
    "BernoulliNB_classifier.train(training_set)\n",
    "\n",
    "print(\"BernoulliNB_classifier Algo Accuracy: \", (nltk.classify.accuracy(BernoulliNB_classifier, testing_set)) * 100)\n",
    "\n",
    "# LogisticRegression\n",
    "\n",
    "LogisticRegression_classifier = SklearnClassifier(LogisticRegression())\n",
    "LogisticRegression_classifier.train(training_set)\n",
    "\n",
    "print(\"LogisticRegression_classifier Algo Accuracy: \", (nltk.classify.accuracy(LogisticRegression_classifier, testing_set)) * 100)\n",
    "\n",
    "# SGDClassifier\n",
    "\n",
    "SGDClassifier_classifier = SklearnClassifier(SGDClassifier())\n",
    "SGDClassifier_classifier.train(training_set)\n",
    "\n",
    "print(\"SGDClassifier_classifier Algo Accuracy: \", (nltk.classify.accuracy(SGDClassifier_classifier, testing_set)) * 100)\n",
    "\n",
    "# LinearSVC\n",
    "\n",
    "LinearSVC_classifier = SklearnClassifier(LinearSVC())\n",
    "LinearSVC_classifier.train(training_set)\n",
    "\n",
    "print(\"LinearSVC_classifier Algo Accuracy: \", (nltk.classify.accuracy(LinearSVC_classifier, testing_set)) * 100)\n",
    "\n",
    "# NuSVC\n",
    "\n",
    "NuSVC_classifier = SklearnClassifier(NuSVC())\n",
    "NuSVC_classifier.train(training_set)\n",
    "\n",
    "print(\"NuSVC_classifier Algo Accuracy: \", (nltk.classify.accuracy(NuSVC_classifier, testing_set)) * 100)\n",
    "\n",
    "## Voted Classifier\n",
    "\n",
    "voted_classifier = VoteClassifier(classifier, MNB_classifier, BernoulliNB_classifier, LogisticRegression_classifier, SGDClassifier_classifier, LinearSVC_classifier, NuSVC_classifier)\n",
    "\n",
    "print(\"Voted_classifier Algo Accuracy: \", (nltk.classify.accuracy(voted_classifier, testing_set)) * 100)\n",
    "\n",
    "print(\"Classfication: \",voted_classifier.classify(testing_set[0][0]), \"Confidence %: \", voted_classifier.confidence(testing_set[0][0])*100)\n",
    "print(\"Classfication: \",voted_classifier.classify(testing_set[1][0]), \"Confidence %: \", voted_classifier.confidence(testing_set[1][0])*100)\n",
    "print(\"Classfication: \",voted_classifier.classify(testing_set[2][0]), \"Confidence %: \", voted_classifier.confidence(testing_set[2][0])*100)\n",
    "print(\"Classfication: \",voted_classifier.classify(testing_set[3][0]), \"Confidence %: \", voted_classifier.confidence(testing_set[3][0])*100)\n",
    "print(\"Classfication: \",voted_classifier.classify(testing_set[4][0]), \"Confidence %: \", voted_classifier.confidence(testing_set[4][0])*100)\n",
    "print(\"Classfication: \",voted_classifier.classify(testing_set[5][0]), \"Confidence %: \", voted_classifier.confidence(testing_set[5][0])*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigating Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Original Naive Bayes Algo Accuracy:  77.0\nMNB_classifier Algo Accuracy:  77.0\nBernoulliNB_classifier Algo Accuracy:  77.0\nLogisticRegression_classifier Algo Accuracy:  80.0\nSGDClassifier_classifier Algo Accuracy:  82.0\nLinearSVC_classifier Algo Accuracy:  81.0\nNuSVC_classifier Algo Accuracy:  83.0\nVoted_classifier Algo Accuracy:  77.0\n"
    }
   ],
   "source": [
    "import nltk\n",
    "import random\n",
    "from nltk.corpus import movie_reviews\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "\n",
    "from nltk.classify import ClassifierI\n",
    "from statistics import mode\n",
    "\n",
    "class VoteClassifier(ClassifierI):\n",
    "\n",
    "    def __init__(self, *classifiers):\n",
    "        self._classifiers = classifiers\n",
    "\n",
    "    def classify(self, features):\n",
    "        votes = []\n",
    "\n",
    "        for c in self._classifiers:\n",
    "            v = c.classify(features)\n",
    "            votes.append(v)\n",
    "            return mode(votes)\n",
    "\n",
    "    def confidence(self, features):\n",
    "        votes = []\n",
    "\n",
    "        for c in self._classifiers:\n",
    "            v = c.classify(features)\n",
    "            votes.append(v)\n",
    "        choice_votes = votes.count(mode(votes))\n",
    "        conf = choice_votes / len(votes)\n",
    "        return conf\n",
    "\n",
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "             for category in movie_reviews.categories()\n",
    "             for fileid in movie_reviews.fileids(category)]\n",
    "\n",
    "# random.shuffle(documents)\n",
    "\n",
    "all_words = []\n",
    "\n",
    "for w in movie_reviews.words():\n",
    "    all_words.append(w.lower())\n",
    "\n",
    "all_words = nltk.FreqDist(all_words)\n",
    "\n",
    "word_features = list(all_words.keys())[:3000]\n",
    "\n",
    "def find_features(document):\n",
    "    words = set(document)\n",
    "    features = {}\n",
    "    for w in word_features:\n",
    "        features[w] = (w in words)\n",
    "\n",
    "    return features\n",
    "\n",
    "featuresets = [(find_features(rev), category) for (rev, category) in documents]\n",
    "\n",
    "# positive data --------------------- Checking result for Positive Reviews Data\n",
    "training_set = featuresets[:1900]\n",
    "testing_set = featuresets[1900:]\n",
    "\n",
    "# Original\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(training_set)\n",
    "\n",
    "print(\"Original Naive Bayes Algo Accuracy: \", (nltk.classify.accuracy(classifier, testing_set)) * 100)\n",
    "\n",
    "# Multinomial\n",
    "\n",
    "MNB_classifier = SklearnClassifier(MultinomialNB())\n",
    "MNB_classifier.train(training_set)\n",
    "\n",
    "print(\"MNB_classifier Algo Accuracy: \", (nltk.classify.accuracy(MNB_classifier, testing_set)) * 100)\n",
    "\n",
    "# BernoulliNB\n",
    "\n",
    "BernoulliNB_classifier = SklearnClassifier(BernoulliNB())\n",
    "BernoulliNB_classifier.train(training_set)\n",
    "\n",
    "print(\"BernoulliNB_classifier Algo Accuracy: \", (nltk.classify.accuracy(BernoulliNB_classifier, testing_set)) * 100)\n",
    "\n",
    "# LogisticRegression\n",
    "\n",
    "LogisticRegression_classifier = SklearnClassifier(LogisticRegression())\n",
    "LogisticRegression_classifier.train(training_set)\n",
    "\n",
    "print(\"LogisticRegression_classifier Algo Accuracy: \", (nltk.classify.accuracy(LogisticRegression_classifier, testing_set)) * 100)\n",
    "\n",
    "# SGDClassifier\n",
    "\n",
    "SGDClassifier_classifier = SklearnClassifier(SGDClassifier())\n",
    "SGDClassifier_classifier.train(training_set)\n",
    "\n",
    "print(\"SGDClassifier_classifier Algo Accuracy: \", (nltk.classify.accuracy(SGDClassifier_classifier, testing_set)) * 100)\n",
    "\n",
    "# LinearSVC\n",
    "\n",
    "LinearSVC_classifier = SklearnClassifier(LinearSVC())\n",
    "LinearSVC_classifier.train(training_set)\n",
    "\n",
    "print(\"LinearSVC_classifier Algo Accuracy: \", (nltk.classify.accuracy(LinearSVC_classifier, testing_set)) * 100)\n",
    "\n",
    "# NuSVC\n",
    "\n",
    "NuSVC_classifier = SklearnClassifier(NuSVC())\n",
    "NuSVC_classifier.train(training_set)\n",
    "\n",
    "print(\"NuSVC_classifier Algo Accuracy: \", (nltk.classify.accuracy(NuSVC_classifier, testing_set)) * 100)\n",
    "\n",
    "## Voted Classifier\n",
    "\n",
    "voted_classifier = VoteClassifier(classifier, MNB_classifier, BernoulliNB_classifier, LogisticRegression_classifier, SGDClassifier_classifier, LinearSVC_classifier, NuSVC_classifier)\n",
    "\n",
    "print(\"Voted_classifier Algo Accuracy: \", (nltk.classify.accuracy(voted_classifier, testing_set)) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Original Naive Bayes Algo Accuracy:  79.0\nMNB_classifier Algo Accuracy:  80.0\nBernoulliNB_classifier Algo Accuracy:  80.0\nLogisticRegression_classifier Algo Accuracy:  73.0\nSGDClassifier_classifier Algo Accuracy:  70.0\nLinearSVC_classifier Algo Accuracy:  72.0\nNuSVC_classifier Algo Accuracy:  77.0\nVoted_classifier Algo Accuracy:  79.0\n"
    }
   ],
   "source": [
    "import nltk\n",
    "import random\n",
    "from nltk.corpus import movie_reviews\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "\n",
    "from nltk.classify import ClassifierI\n",
    "from statistics import mode\n",
    "\n",
    "class VoteClassifier(ClassifierI):\n",
    "\n",
    "    def __init__(self, *classifiers):\n",
    "        self._classifiers = classifiers\n",
    "\n",
    "    def classify(self, features):\n",
    "        votes = []\n",
    "\n",
    "        for c in self._classifiers:\n",
    "            v = c.classify(features)\n",
    "            votes.append(v)\n",
    "            return mode(votes)\n",
    "\n",
    "    def confidence(self, features):\n",
    "        votes = []\n",
    "\n",
    "        for c in self._classifiers:\n",
    "            v = c.classify(features)\n",
    "            votes.append(v)\n",
    "        choice_votes = votes.count(mode(votes))\n",
    "        conf = choice_votes / len(votes)\n",
    "        return conf\n",
    "\n",
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "             for category in movie_reviews.categories()\n",
    "             for fileid in movie_reviews.fileids(category)]\n",
    "\n",
    "# random.shuffle(documents)\n",
    "\n",
    "all_words = []\n",
    "\n",
    "for w in movie_reviews.words():\n",
    "    all_words.append(w.lower())\n",
    "\n",
    "all_words = nltk.FreqDist(all_words)\n",
    "\n",
    "word_features = list(all_words.keys())[:3000]\n",
    "\n",
    "def find_features(document):\n",
    "    words = set(document)\n",
    "    features = {}\n",
    "    for w in word_features:\n",
    "        features[w] = (w in words)\n",
    "\n",
    "    return features\n",
    "\n",
    "featuresets = [(find_features(rev), category) for (rev, category) in documents]\n",
    "\n",
    "# negative data --------------------- Checking result for Negative Reviews Data\n",
    "training_set = featuresets[100:]\n",
    "testing_set = featuresets[:100]\n",
    "\n",
    "# Original\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(training_set)\n",
    "\n",
    "print(\"Original Naive Bayes Algo Accuracy: \", (nltk.classify.accuracy(classifier, testing_set)) * 100)\n",
    "\n",
    "# Multinomial\n",
    "\n",
    "MNB_classifier = SklearnClassifier(MultinomialNB())\n",
    "MNB_classifier.train(training_set)\n",
    "\n",
    "print(\"MNB_classifier Algo Accuracy: \", (nltk.classify.accuracy(MNB_classifier, testing_set)) * 100)\n",
    "\n",
    "# BernoulliNB\n",
    "\n",
    "BernoulliNB_classifier = SklearnClassifier(BernoulliNB())\n",
    "BernoulliNB_classifier.train(training_set)\n",
    "\n",
    "print(\"BernoulliNB_classifier Algo Accuracy: \", (nltk.classify.accuracy(BernoulliNB_classifier, testing_set)) * 100)\n",
    "\n",
    "# LogisticRegression\n",
    "\n",
    "LogisticRegression_classifier = SklearnClassifier(LogisticRegression())\n",
    "LogisticRegression_classifier.train(training_set)\n",
    "\n",
    "print(\"LogisticRegression_classifier Algo Accuracy: \", (nltk.classify.accuracy(LogisticRegression_classifier, testing_set)) * 100)\n",
    "\n",
    "# SGDClassifier\n",
    "\n",
    "SGDClassifier_classifier = SklearnClassifier(SGDClassifier())\n",
    "SGDClassifier_classifier.train(training_set)\n",
    "\n",
    "print(\"SGDClassifier_classifier Algo Accuracy: \", (nltk.classify.accuracy(SGDClassifier_classifier, testing_set)) * 100)\n",
    "\n",
    "# LinearSVC\n",
    "\n",
    "LinearSVC_classifier = SklearnClassifier(LinearSVC())\n",
    "LinearSVC_classifier.train(training_set)\n",
    "\n",
    "print(\"LinearSVC_classifier Algo Accuracy: \", (nltk.classify.accuracy(LinearSVC_classifier, testing_set)) * 100)\n",
    "\n",
    "# NuSVC\n",
    "\n",
    "NuSVC_classifier = SklearnClassifier(NuSVC())\n",
    "NuSVC_classifier.train(training_set)\n",
    "\n",
    "print(\"NuSVC_classifier Algo Accuracy: \", (nltk.classify.accuracy(NuSVC_classifier, testing_set)) * 100)\n",
    "\n",
    "## Voted Classifier\n",
    "\n",
    "voted_classifier = VoteClassifier(classifier, MNB_classifier, BernoulliNB_classifier, LogisticRegression_classifier, SGDClassifier_classifier, LinearSVC_classifier, NuSVC_classifier)\n",
    "\n",
    "print(\"Voted_classifier Algo Accuracy: \", (nltk.classify.accuracy(voted_classifier, testing_set)) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Better Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xf3 in position 4645: invalid continuation byte",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-f7808b9e80f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mshort_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"short_reviews/positive.txt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0mshort_neg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"short_reviews/negative.txt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.8/3.8.3_2/Frameworks/Python.framework/Versions/3.8/lib/python3.8/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsumed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[0;31m# keep undecoded input until the next call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconsumed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xf3 in position 4645: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import random\n",
    "from nltk.corpus import movie_reviews\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "\n",
    "from nltk.classify import ClassifierI\n",
    "from statistics import mode\n",
    "\n",
    "class VoteClassifier(ClassifierI):\n",
    "\n",
    "    def __init__(self, *classifiers):\n",
    "        self._classifiers = classifiers\n",
    "\n",
    "    def classify(self, features):\n",
    "        votes = []\n",
    "\n",
    "        for c in self._classifiers:\n",
    "            v = c.classify(features)\n",
    "            votes.append(v)\n",
    "            return mode(votes)\n",
    "\n",
    "    def confidence(self, features):\n",
    "        votes = []\n",
    "\n",
    "        for c in self._classifiers:\n",
    "            v = c.classify(features)\n",
    "            votes.append(v)\n",
    "        choice_votes = votes.count(mode(votes))\n",
    "        conf = choice_votes / len(votes)\n",
    "        return conf\n",
    "\n",
    "short_pos = open(\"short_reviews/positive.txt\",\"r\").read()\n",
    "short_neg = open(\"short_reviews/negative.txt\",\"r\").read()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for r in short_pos.split('\\n'):\n",
    "    documents.append( (r, \"pos\") )\n",
    "\n",
    "for r in short_neg.split('\\n'):\n",
    "    documents.append( (r, \"neg\") )\n",
    "\n",
    "all_words = []\n",
    "\n",
    "short_pos_words = word_tokenize(short_pos)\n",
    "short_neg_words = word_tokenize(short_neg)\n",
    "\n",
    "for w in short_pos_words:\n",
    "    all_words.append(w.lower())\n",
    "\n",
    "for w in short_neg_words:\n",
    "    all_words.append(w.lower())\n",
    "\n",
    "all_words = nltk.FreqDist(all_words)\n",
    "\n",
    "word_features = list(all_words.keys())[:5000]\n",
    "\n",
    "def find_features(document):\n",
    "    words = word_tokenize(document)\n",
    "    features = {}\n",
    "    for w in word_features:\n",
    "        features[w] = (w in words)\n",
    "\n",
    "    return features\n",
    "\n",
    "featuresets = [(find_features(rev), category) for (rev, category) in documents]\n",
    "\n",
    "random.shuffle(featuresets)\n",
    "\n",
    "training_set = featuresets[:10000]\n",
    "testing_set = featuresets[10000:]\n",
    "\n",
    "# Original\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(training_set)\n",
    "\n",
    "print(\"Original Naive Bayes Algo Accuracy: \", (nltk.classify.accuracy(classifier, testing_set)) * 100)\n",
    "\n",
    "# Multinomial\n",
    "\n",
    "MNB_classifier = SklearnClassifier(MultinomialNB())\n",
    "MNB_classifier.train(training_set)\n",
    "\n",
    "print(\"MNB_classifier Algo Accuracy: \", (nltk.classify.accuracy(MNB_classifier, testing_set)) * 100)\n",
    "\n",
    "# BernoulliNB\n",
    "\n",
    "BernoulliNB_classifier = SklearnClassifier(BernoulliNB())\n",
    "BernoulliNB_classifier.train(training_set)\n",
    "\n",
    "print(\"BernoulliNB_classifier Algo Accuracy: \", (nltk.classify.accuracy(BernoulliNB_classifier, testing_set)) * 100)\n",
    "\n",
    "# LogisticRegression\n",
    "\n",
    "LogisticRegression_classifier = SklearnClassifier(LogisticRegression())\n",
    "LogisticRegression_classifier.train(training_set)\n",
    "\n",
    "print(\"LogisticRegression_classifier Algo Accuracy: \", (nltk.classify.accuracy(LogisticRegression_classifier, testing_set)) * 100)\n",
    "\n",
    "# SGDClassifier\n",
    "\n",
    "SGDClassifier_classifier = SklearnClassifier(SGDClassifier())\n",
    "SGDClassifier_classifier.train(training_set)\n",
    "\n",
    "print(\"SGDClassifier_classifier Algo Accuracy: \", (nltk.classify.accuracy(SGDClassifier_classifier, testing_set)) * 100)\n",
    "\n",
    "# LinearSVC\n",
    "\n",
    "LinearSVC_classifier = SklearnClassifier(LinearSVC())\n",
    "LinearSVC_classifier.train(training_set)\n",
    "\n",
    "print(\"LinearSVC_classifier Algo Accuracy: \", (nltk.classify.accuracy(LinearSVC_classifier, testing_set)) * 100)\n",
    "\n",
    "# NuSVC\n",
    "\n",
    "NuSVC_classifier = SklearnClassifier(NuSVC())\n",
    "NuSVC_classifier.train(training_set)\n",
    "\n",
    "print(\"NuSVC_classifier Algo Accuracy: \", (nltk.classify.accuracy(NuSVC_classifier, testing_set)) * 100)\n",
    "\n",
    "## Voted Classifier\n",
    "\n",
    "voted_classifier = VoteClassifier(classifier, MNB_classifier, BernoulliNB_classifier, LogisticRegression_classifier, SGDClassifier_classifier, LinearSVC_classifier, NuSVC_classifier)\n",
    "\n",
    "print(\"Voted_classifier Algo Accuracy: \", (nltk.classify.accuracy(voted_classifier, testing_set)) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38364bit054245dcf21e4c25b7b8d8cc669b6593",
   "display_name": "Python 3.8.3 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}